{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code2Doc-usingGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcUTzYnjk6fBdOnodHEwoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisashimabucoro/NMA-Project-Code-Summarization/blob/main/Code2Doc_usingGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preliminaries**"
      ],
      "metadata": {
        "id": "WIjWyvsybAPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers &> /dev/null\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import unicodedata\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "id": "X8XWLGRUiNSr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61avk545hCV8",
        "outputId": "113ebde5-3feb-46a9-edde-8d2d6774ee55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount gdrive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic EDA**"
      ],
      "metadata": {
        "id": "XareqRpeana6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_json('/content/gdrive/Shareddrives/Dolma2/Datasets/python/train.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "T_YZCJLOiPeO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_df) # samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7lw9Kybi2f7",
        "outputId": "1fc5eaa1-7270-468d-e5a7-0a102ca2075f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "251820"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = data_df.loc[:,['code_tokens', 'docstring_tokens']] # removing extra columns\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ry06m5dHjXxe",
        "outputId": "14b1b9a6-9f1f-4c19-fb84-0f44cdbff7c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              code_tokens  \\\n",
              "0       [def, split_phylogeny, (, p, ,, level, =, \"s\",...   \n",
              "1       [def, ensure_dir, (, d, ), :, if, not, os, ., ...   \n",
              "2       [def, file_handle, (, fnh, ,, mode, =, \"rU\", )...   \n",
              "3       [def, gather_categories, (, imap, ,, header, ,...   \n",
              "4       [def, parse_unifrac, (, unifracFN, ), :, with,...   \n",
              "...                                                   ...   \n",
              "251815  [def, setCachedDataKey, (, engineVersionHash, ...   \n",
              "251816  [def, writeFile, (, filename, ,, data, ), :, w...   \n",
              "251817  [def, patchFile, (, filename, ,, replacements,...   \n",
              "251818  [def, escapePathForShell, (, path, ), :, if, p...   \n",
              "251819  [def, join, (, delim, ,, items, ,, quotes, =, ...   \n",
              "\n",
              "                                         docstring_tokens  \n",
              "0       [Return, either, the, full, or, truncated, ver...  \n",
              "1       [Check, to, make, sure, the, supplied, directo...  \n",
              "2       [Takes, either, a, file, path, or, an, open, f...  \n",
              "3       [Find, the, user, specified, categories, in, t...  \n",
              "4       [Parses, the, unifrac, results, file, into, a,...  \n",
              "...                                                   ...  \n",
              "251815  [Sets, the, cached, data, value, for, the, spe...  \n",
              "251816                        [Writes, data, to, a, file]  \n",
              "251817  [Applies, the, supplied, list, of, replacement...  \n",
              "251818  [Escapes, a, filesystem, path, for, use, as, a...  \n",
              "251819  [Joins, the, supplied, list, of, strings, afte...  \n",
              "\n",
              "[251820 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6c615b9-bff0-439f-ae1c-e4654567bdec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code_tokens</th>\n",
              "      <th>docstring_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[def, split_phylogeny, (, p, ,, level, =, \"s\",...</td>\n",
              "      <td>[Return, either, the, full, or, truncated, ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[def, ensure_dir, (, d, ), :, if, not, os, ., ...</td>\n",
              "      <td>[Check, to, make, sure, the, supplied, directo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[def, file_handle, (, fnh, ,, mode, =, \"rU\", )...</td>\n",
              "      <td>[Takes, either, a, file, path, or, an, open, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[def, gather_categories, (, imap, ,, header, ,...</td>\n",
              "      <td>[Find, the, user, specified, categories, in, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[def, parse_unifrac, (, unifracFN, ), :, with,...</td>\n",
              "      <td>[Parses, the, unifrac, results, file, into, a,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251815</th>\n",
              "      <td>[def, setCachedDataKey, (, engineVersionHash, ...</td>\n",
              "      <td>[Sets, the, cached, data, value, for, the, spe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251816</th>\n",
              "      <td>[def, writeFile, (, filename, ,, data, ), :, w...</td>\n",
              "      <td>[Writes, data, to, a, file]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251817</th>\n",
              "      <td>[def, patchFile, (, filename, ,, replacements,...</td>\n",
              "      <td>[Applies, the, supplied, list, of, replacement...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251818</th>\n",
              "      <td>[def, escapePathForShell, (, path, ), :, if, p...</td>\n",
              "      <td>[Escapes, a, filesystem, path, for, use, as, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251819</th>\n",
              "      <td>[def, join, (, delim, ,, items, ,, quotes, =, ...</td>\n",
              "      <td>[Joins, the, supplied, list, of, strings, afte...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>251820 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c615b9-bff0-439f-ae1c-e4654567bdec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6c615b9-bff0-439f-ae1c-e4654567bdec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6c615b9-bff0-439f-ae1c-e4654567bdec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list(train_df['docstring_tokens']\" \".join())\n",
        "for i in train_df['docstring_tokens']:\n",
        "  j = \" \".join(i)\n",
        "  print(j)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZlbFXJ3DuZT",
        "outputId": "4dea1f19-de14-4269-b15d-45c5ff8bc3d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return either the full or truncated version of a QIIME - formatted taxonomy string .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docstring = list(train_df['docstring_tokens'].apply(lambda x: \" \".join(x)))\n",
        "code = list(train_df['code_tokens'].apply(lambda x: \" \".join(x)))\n",
        "combined = []\n",
        "for i, x in enumerate(docstring):\n",
        "  pair = []\n",
        "  pair.append(docstring[i])\n",
        "  pair.append(code[i])\n",
        "  combined.append(pair)\n",
        "  print(combined)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyOGLB5iFR1j",
        "outputId": "0c6f1c74-d6ba-4b94-9dec-2f52c59a65b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Return either the full or truncated version of a QIIME - formatted taxonomy string .', 'def split_phylogeny ( p , level = \"s\" ) : level = level + \"__\" result = p . split ( level ) return result [ 0 ] + level + result [ 1 ] . split ( \";\" ) [ 0 ]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "    self.n_words = 3  # Count SOS and EOS and PAD\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1\n",
        "\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s\n",
        "\n",
        "\n",
        "def readLangs(lang1, lang2, data, reverse=False):\n",
        "  print(\"Reading lines...\")\n",
        "\n",
        "  docstring = list(train_df['docstring_tokens'].apply(lambda x: \" \".join(x)))\n",
        "  code = list(train_df['code_tokens'].apply(lambda x: \" \".join(x)))\n",
        "  combined = []\n",
        "  for i, x in enumerate(docstring):\n",
        "    pair = []\n",
        "    pair.append(docstring[i])\n",
        "    pair.append(code[i])\n",
        "    combined.append(pair)\n",
        "    #print(combined[:5])\n",
        "  '''\n",
        "  # Read the file and split into lines\n",
        "  lines = io.open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "      read().strip().split('\\n')\n",
        "\n",
        "  # Split every line into pairs and normalize\n",
        "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "  print(pairs[-5:])\n",
        "\n",
        "  train_df\n",
        "  '''\n",
        "\n",
        "  # Reverse pairs, make Lang instances\n",
        "  if reverse:\n",
        "      pairs = [list(reversed(p)) for p in combined]\n",
        "      input_lang = Lang(lang2)\n",
        "      output_lang = Lang(lang1)\n",
        "  else:\n",
        "      input_lang = Lang(lang1)\n",
        "      output_lang = Lang(lang2)\n",
        "  print(combined)\n",
        "  return input_lang, output_lang, combined"
      ],
      "metadata": {
        "id": "MJXsr-o_DC3z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 1000\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "      len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]\n",
        "\n"
      ],
      "metadata": {
        "id": "E6GcR7otI8_q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, data, reverse=False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, data, reverse)\n",
        "  print(pairs)\n",
        "  print(\"Read %s sentence pairs\" % len(pairs))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print(pairs)\n",
        "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print(\"Counted words:\")\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('cod', 'des', train_df, True)\n",
        "print(pairs)"
      ],
      "metadata": {
        "id": "j427CqutJCum",
        "outputId": "ce8ea19f-22e4-4a48-ee2b-ddc7be3cb729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lang(lang, top_k=100):\n",
        "  words = list(lang.word2count.keys())\n",
        "  words.sort(key=lambda w: lang.word2count[w], reverse=True)\n",
        "  print(words[:top_k])\n",
        "  count_occurences = sum(lang.word2count.values())\n",
        "\n",
        "  accumulated = 0\n",
        "  counter = 0\n",
        "\n",
        "  while accumulated < count_occurences * 0.8:\n",
        "    accumulated += lang.word2count[words[counter]]\n",
        "    counter += 1\n",
        "\n",
        "  print(f\"The {counter * 100 / len(words)}% most common words \"\n",
        "        f\"account for the {accumulated * 100 / count_occurences}% of the occurrences\")\n",
        "  plt.bar(range(100), [lang.word2count[w] for w in words[:top_k]])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "YzcYpcUePYBP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lang(input_lang)"
      ],
      "metadata": {
        "id": "rkWnNVA3PaRB",
        "outputId": "1369fbd1-b20a-45d0-b787-0395e80c3ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.', 'the', 'a', 'to', 'of', 'and', 'for', 'in', 'from', 'is', 'an', '-', 'given', 'with', 'if', 'that', 'Return', 'file', 'all', 'this', 'Returns', 'list', 'or', 'on', 'by', 'data', 'be', 'as', 'object', 'it', 'Get', 'function', 'value', 'string', 'into', 'return', 'are', 'name', 's', 'new', 'not', 'specified', 'Create', 'This', 'method', 'will', 'set', 'current', 'returns', 'user', 'values', 'If', 'using', 'path', 'The', 'one', 'instance', 'key', 'each', 'at', 'Add', 'type', 'which', 'dictionary', 'number', 'used', 'can', 'request', 'files', 'message', 'Set', 'model', 'based', 'any', 'its', 'Check', 'Convert', 'command', 'when', 'time', 'node', 'input', 'class', 'dict', 'has', 'directory', 'text', 'information', 'single', 'default', 'line', 'only', 'state', 'Creates', 'output', 'format', 'A', 'objects', 'version', 'configuration']\n",
            "The 1.476028981039001% most common words account for the 80.00089637643329% of the occurrences\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lang(output_lang)"
      ],
      "metadata": {
        "id": "Qzh34WHkPfrR",
        "outputId": "4ece7b69-84f6-4d1b-cf9a-2e39764fda0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['(', ')', '.', ',', '=', ':', 'self', '[', ']', 'if', 'return', 'def', 'in', 'None', 'for', 'not', '0', '1', 'else', '+', '==', 'is', 'name', 'raise', 'data', '-', 'path', '{', '}', '*', 'True', 'False', 'format', 'value', 'and', 'len', 'append', 'get', 'key', 'i', '%', '**', 'kwargs', 'args', 'except', 'np', 'try', 'os', 'x', 'elif', 'isinstance', 'or', 'str', '2', 'result', \"'\", 'join', '+=', 'as', '\"', 'to', 'a', 'f', '', 'int', 'with', '!=', 'k', 'e', 'ValueError', 'cls', 'v', 'list', '>', 'response', 'request', 'ret', 'logger', 'line', 'url', \"''\", '/', 'debug', 'print', 'config', 'obj', 'params', 's', 'info', 'log', 'index', 'filename', 'type', 'msg', 'node', 'items', 'split', 'r', 'p', 'text']\n",
            "The 0.1337243917266665% most common words account for the 80.00199674473694% of the occurrences\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input)#.view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self, batch_size):\n",
        "    return torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output))\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "def to_train(input_lang, output_lang, pairs, max_len=MAX_LENGTH+2):\n",
        "  x_input = []\n",
        "  x_output = []\n",
        "  target = []\n",
        "  for i, o in pairs:\n",
        "    s_i = [2] * max_len + [0] + [input_lang.word2index[w] for w in i.split(\" \")] + [1]\n",
        "    s_o = [0] + [output_lang.word2index[w] for w in o.split(\" \")] + [1] + [2] * max_len\n",
        "    s_to = s_o[1:] + [2]\n",
        "    x_input.append(s_i[-max_len:])\n",
        "    x_output.append(s_o[:max_len])\n",
        "    target.append(s_to[:max_len])\n",
        "  return x_input, x_output, target"
      ],
      "metadata": {
        "id": "pVVjFWKIPjiu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_input, x_partial, y = to_train(input_lang, output_lang, pairs)"
      ],
      "metadata": {
        "id": "UpE0ELbUPrAe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Representation of an input sentece:')\n",
        "print(x_input[0])\n",
        "print(' '.join([input_lang.index2word[w] for w in x_input[0]]))\n",
        "print('\\nRepresentation of an partial sentece:')\n",
        "print(x_partial[0])\n",
        "print(' '.join([output_lang.index2word[w] for w in x_partial[0]]))\n",
        "print('\\nRepresentation of an target sentece:')\n",
        "print(y[0])\n",
        "print(' '.join([output_lang.index2word[w] for w in y[0]]))"
      ],
      "metadata": {
        "id": "lkGRBdQDPtlG",
        "outputId": "16013734-b50f-4ab9-b1c2-3a3c3db32e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representation of an input sentece:\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1]\n",
            "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD SOS Return either the full or truncated version of a QIIME - formatted taxonomy string . EOS\n",
            "\n",
            "Representation of an partial sentece:\n",
            "[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 8, 9, 8, 13, 14, 15, 9, 6, 16, 17, 5, 8, 11, 18, 15, 19, 20, 21, 13, 8, 13, 15, 19, 22, 21, 16, 17, 5, 23, 11, 19, 20, 21, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "SOS def split_phylogeny ( p , level = \"s\" ) : level = level + \"__\" result = p . split ( level ) return result [ 0 ] + level + result [ 1 ] . split ( \";\" ) [ 0 ] EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
            "\n",
            "Representation of an target sentece:\n",
            "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 8, 9, 8, 13, 14, 15, 9, 6, 16, 17, 5, 8, 11, 18, 15, 19, 20, 21, 13, 8, 13, 15, 19, 22, 21, 16, 17, 5, 23, 11, 19, 20, 21, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "def split_phylogeny ( p , level = \"s\" ) : level = level + \"__\" result = p . split ( level ) return result [ 0 ] + level + result [ 1 ] . split ( \";\" ) [ 0 ] EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(encoder, decoder, input, output):\n",
        "  _, hidden = encoder(input, encoder.initHidden(input.shape[0]))\n",
        "  out, _ = decoder(output, hidden)\n",
        "  return out\n",
        "\n",
        "def train(encoder, decoder, loss, input, output, target, learning_rate=0.001, epochs=10, batch_size=100):\n",
        "\n",
        "  plot_losses = []\n",
        "  plot_full_losses = []\n",
        "\n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "  for _ in tqdm(range(epochs)):\n",
        "    c_input, c_output, c_target = shuffle(input, output, target)\n",
        "    c_input = torch.tensor(c_input, dtype=torch.long, device=device)\n",
        "    c_output = torch.tensor(c_output, dtype=torch.long, device=device)\n",
        "    c_target = torch.tensor(c_target, dtype=torch.long, device=device)\n",
        "    acc_loss = 0\n",
        "    for i in range(0, c_target.shape[0], batch_size):\n",
        "      c_batch_size = c_target[i:i+batch_size, ...].shape[0]\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "\n",
        "      out = predict(encoder, decoder, c_input[i:i+batch_size, ...], c_output[i:i+batch_size, ...])\n",
        "      #Reshapes the output and target to use the expected loss format.\n",
        "      # N x Classes for the output\n",
        "      # N for the targets\n",
        "      # Where N is the batch size\n",
        "      out = out.reshape(c_batch_size * c_input.shape[1], -1)\n",
        "      r_target = c_target[i:i+batch_size, ...].reshape(c_batch_size * c_input.shape[1])\n",
        "\n",
        "      c_loss = loss(out, r_target)\n",
        "      # Mask the errors for padding as they are not usefull!\n",
        "      valid = torch.where(r_target == 2, 0, 1)\n",
        "      c_loss = c_loss * valid\n",
        "      c_loss = torch.sum(c_loss) #/ torch.sum(valid)\n",
        "\n",
        "      c_loss.backward()\n",
        "\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "      plot_full_losses.append(c_loss.detach().cpu().numpy())\n",
        "      acc_loss += c_loss.detach().cpu().numpy()\n",
        "    plot_losses.append(acc_loss /math.ceil(c_target.shape[0] / batch_size))\n",
        "  return plot_losses, plot_full_losses"
      ],
      "metadata": {
        "id": "5IHzk4nkPwIe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 300\n",
        "num_epochs = 10  # Change this to 50 (original value!)\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "epoch_error, batch_error = train(encoder, decoder,\n",
        "                                 nn.NLLLoss(reduction='none'),\n",
        "                                 x_input, x_partial, y,\n",
        "                                 epochs=num_epochs)"
      ],
      "metadata": {
        "id": "6MkfziMlPwZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(epoch_error)\n",
        "#print(batch_error)\n",
        "\n",
        "plt.plot(batch_error)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('minibatch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_error)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "phruRlJ9P4jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = predict(encoder, decoder, torch.tensor([x_input[100]],\n",
        "                                           dtype=torch.long,\n",
        "                                           device=device),\n",
        "            torch.tensor([x_partial[100]], dtype=torch.long, device=device))\n",
        "\n",
        "p = p.detach().numpy()"
      ],
      "metadata": {
        "id": "FE20nh29QetB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.argmax(p, axis=-1))\n",
        "print(x_partial[40])"
      ],
      "metadata": {
        "id": "lhB6hHOpQz56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tqkBnZaBlZDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}